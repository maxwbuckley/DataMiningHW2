---
title: 'Data Mining Homework 2: Premier League'
author: "Max Buckley"
date: "22/03/2016"
output: pdf_document
---

In this assignment I aim to explore throughly the provided dataset of Premier League soccer matches. From the brief the objective is:

>Your task is to analyse Premier League match data provided since 2010 up to and including last weekend (6 March 2016). You should attempt to uncover interesting and potentially useful patterns and rules which might be used to determine the outcome of the remaining matches in the 2016 league.

I will break my analysis into its logical steps so that I start with data cleaning and preperation, progress to data exploration, and then lastly attempt data modelling and prediction. I will include all my code in the interests of reproducable research.

An interesting thing to note is I have absolutely no interest in soccer I may be unaware of or ask naive questions of the data vis-a-vis the soccer afficianados in the class.

#Data Cleaning

```{r}
# Libraries.
library("plyr")
# Best plotting library ever
library("ggplot2")
# For data munging
library("reshape")
# More data munginf
library("reshape2")
# Same
library("plyr")
# Recursive Partitioning decision trees
library("rpart")
# The party package provides nonparametric regression trees
# for nominal, ordinal, numeric, censored, and multivariate
# responses.
library("party")
# Package for classification and regresssion.
library("caret")
# Package for fitting random forests.
library("randomForest")

# Clear R environment.
rm(list=ls())
# Set working directory .
setwd("~/UCD/DataMining/HW2/")

output_dir <- "CleanedData"
input_dir <- "InputData"

input_csv_files <- dir(input_dir)

# List to store all the data frames.
df_list <- list()
for(i in 1:length(input_csv_files)){
  file <- input_csv_files[i]
  df <- read.csv(paste0(input_dir, "/", file),
                 stringsAsFactors=FALSE)
  # Store a season indicator.
  df$Season <- gsub(".csv", "", file)
  df_list[[i]] <- df
}

# Combine all the data frames into one.
cleaned_data <- rbind.fill(df_list[1:i])
# Format date as proper R date object.
cleaned_data$Date <- as.Date(cleaned_data$Date, "%d/%m/%y")
# Factor desired character columns.
cleaned_data$FTR <- as.factor(cleaned_data$FTR)
cleaned_data$HTR <- as.factor(cleaned_data$HTR)
cleaned_data$HomeTeam <- as.factor(cleaned_data$HomeTeam)
cleaned_data$AwayTeam <- as.factor(cleaned_data$AwayTeam)
cleaned_data$Referee <- as.factor(cleaned_data$Referee)
cleaned_data$Season <- as.factor(gsub("20(\\d+)_(\\d+)","\\1/\\2",cleaned_data$Season,))

# Remove Division as it is a constant. It adds no info.
cleaned_data$Div <- NULL

#Calculate points
HomePoints<-rep(1, nrow(cleaned_data))
HomePoints[cleaned_data$FTR=="H"] <- 3
HomePoints[cleaned_data$FTR=="A"] <- 0
cleaned_data$HomePoints <- HomePoints
AwayPoints<-rep(1,nrow(cleaned_data))
AwayPoints[cleaned_data$FTR=="H"] <- 0
AwayPoints[cleaned_data$FTR=="A"] <- 3
cleaned_data$AwayPoints <-AwayPoints
cleaned_data$TotalGoals <-cleaned_data$FTHG + cleaned_data$FTAG


# Save as output to use later. Use .Rda format to preserve R
# type information in addition to data values.
save(cleaned_data, file = paste0(output_dir, "/",
                                 "cleaned_data.Rda"))
```
With some of my data preprocessing I now had a better idea of what my data source looks like and how it is strucutred.

Given the dataset is currently in wide form and quite difficult to work with I decided to switch it to long form. So rather than having the winner and loser in one row I would have one row for each side and I could then more easily aggregate it.

```{r message=FALSE, warning=FALSE}
options(stringsAsFactors=FALSE)

# Clear R environment.
rm(list=ls())

#This will be used to avoid some division by zero errors later.
ratio_offset<-1e-6

# Set working directory .
setwd("~/UCD/DataMining/HW2/")
# This creates an object called cleaned_data in our environment.
load("CleanedData/cleaned_data.Rda")

# Gets our long form dataset. This function doesn't maintain all the columns.
get_long_data <- function(){
  # Take a subset of our data
  # Team names, results, refs and dates/seasons
  subset <- cleaned_data[,c(1:6, 10, 71, 75, 76, 77)]
  # Convet dataset to long form from wide form.
  sub_data <- melt(subset, id=c("Date", "FTHG", "FTAG", 
                                "FTR", "Referee", "Season", 
                                "HomePoints", "AwayPoints", 
                                "TotalGoals"))
  sub_data <- rename(sub_data, c("value" = "TeamName"))
  sub_data <- rename(sub_data, c("variable" = "HomeOrAway"))
  
  # Calculate the respective points for each team.
  sub_data$Points <- 0
  sub_data$Points[sub_data$HomeOrAway=="AwayTeam"] <-
    sub_data$AwayPoints[sub_data$HomeOrAway=="AwayTeam"]
  sub_data$Points[sub_data$HomeOrAway=="HomeTeam"] <-
    sub_data$HomePoints[sub_data$HomeOrAway=="HomeTeam"]
  
  # Create a factor as it can be easier for prediction.
  sub_data$Result<-as.factor(sub_data$Points)
  levels(sub_data$Result)<-c("L","D","W")
  
  sub_data$Goals <-0
  sub_data$Goals[sub_data$HomeOrAway=="AwayTeam"] <-
    sub_data$FTAG[sub_data$HomeOrAway=="AwayTeam"]
  sub_data$Goals[sub_data$HomeOrAway=="HomeTeam"] <-
    sub_data$FTHG[sub_data$HomeOrAway=="HomeTeam"]
  
  # Opponent
  opposition <-cbind.data.frame(rep(cleaned_data$AwayTeam, 2),
                                rep(cleaned_data$HomeTeam, 2))
  vec<-vector()
  for(i in 1:nrow(opposition)){
    if(sub_data$TeamName[i]==opposition[i, 1]){
     vec[i] <- as.character(opposition[i, 2])
    }
    else{
      vec[i] <- as.character(opposition[i, 1])
    }
  }
  sub_data$Opponent <-as.factor(vec)
  
  # Introduce a calculated metric. goal ratio. Which tells us
  # what proportion of the goals in that match that team scored.
  # To prevent division by zero NaNs. The round later removes this.
  sub_data$GoalRatio<-round((sub_data$Goals + ratio_offset)/
                            (sub_data$TotalGoals + ratio_offset),
                             digits=2)
  return(sub_data)
}

sub_data <- get_long_data()

#Take a peek.
head(sub_data[,-c(2:4)])
```

This long form data will be more useful in some instances. Now I can predict win/lose/draw for teams rather than say home/away/draw which would have been confounded by the fact that a given team can be either home or away. An important thing to note is there is now 2 rows per match. One row for the home team and one for the away team. Another benefit off this new structure is that I can now aggregate it. Summing the points for a given team easily.

# Data Exploration
## Who are the best teams?
Naively one would assume that the match result and teams playing would appear to be the most imortant factors. So a question to ask is which teams are the best historically and how are these different teams doing?

```{r message=FALSE, warning=FALSE}
# Take another subset
interestcols<-c("Season", "Date", "HomeOrAway", "Referee",
                "TeamName", "Opponent", "Points", "Goals",
                "TotalGoals", "GoalRatio")
formed_data <- sub_data[, interestcols]


## More exploration
numerical <- formed_data[,-c(1,2,3,4,5,6)]
sum_mat<-aggregate(numerical, by=list(formed_data$Season, 
                                      formed_data$TeamName), 
                   FUN=sum)
mean_mat<-aggregate(numerical, by=list(formed_data$Season, 
                                       formed_data$TeamName
                                       ), FUN=mean)
sum_mat$GoalRatio <- mean_mat$GoalRatio
sum_mat <- rename(sum_mat, c("Group.1"="Season",
                             "Group.2"="TeamName"))
sum_mat<-sum_mat[order(as.character(sum_mat$Season), sum_mat$Points, decreasing=TRUE),]
row.names(sum_mat)<-1:120
sum_mat<-ddply(sum_mat, .(Season), transform, Rank = rank(-Points, ties.method="first"))


p<- ggplot(sum_mat, aes(Season, Points, group=TeamName,
                        colour=TeamName))
p + geom_path(alpha=1)+ labs(title = "Team Points by Season"
                             ) + guides(colour=guide_legend
                                        (ncol=2))
```

Of course we immeadiatly see multiple problems with this chart. One is that the 2015/16 season 
is incomplete so all the lines collapse towards the center. Also maybe it is a better question to
ask what is the rank of any given team in a particular year.


```{r}
p <- ggplot(sum_mat, aes(Season, Rank, group=TeamName,
                        colour=TeamName))
p + geom_path(alpha=1)+ labs(title= "Team Rank by Season") +
  guides(colour=guide_legend(ncol=2))
  
# Look at trends over time
rank_by_season <- cast(sum_mat, TeamName ~Season, mean,   value='Rank')
rank_by_season

```

From this, improved chart we can see that team performance is quite volatile and unpredicatble. Teams can move up and down the leaderboard year to year.
We also see a lot of the teams at the top of the chart tend to be discontinuos as they get relegated due to poor performance. The table at the bottom makes this a little easier to see. The NaN values represent years in which that team did not participate.

Now that I have some idea of what teams are doing well my next exploratory questions are to look at if there are any other interesting relationships.

## Home and Away
```{r}
# How many points on average do you get for a home or away match?
tapply(sub_data$Points, sub_data$HomeOrAway, FUN=mean)


# Examine relationship between home and away results
win_odds<-prop.table(table(cleaned_data$FTR))
win_odds

round(win_odds/min(win_odds),2)

# There is a statistical difference between
t.test(cleaned_data$FTHG, cleaned_data$FTAG, paired=TRUE)

```
It seems my soccer loving friends were correct there seems to be a large difference between home and away performances in favour of home. Home victory is ~50% more likely than an away victory.

## Referees
```{r}
# Are there differences between referees?

tapply(cleaned_data$TotalGoals,cleaned_data$Referee, FUN=mean)

p <- ggplot(cleaned_data, aes(Referee, TotalGoals))
p + geom_boxplot() + geom_jitter() + labs(
  title= "Total Goals by referee.") + theme(axis.ticks = element_blank(), axis.text.x = element_blank())

```

There appears to be no relationship between total goals and referee.

## Half time vs. Full time.
```{r}
# Relationship betwen half time result and full time result.
prop.table(table(cleaned_data$FTR, cleaned_data$HTR),2)

summary(lm(cleaned_data$FTHG~cleaned_data$FTAG))
p <- ggplot(cleaned_data, aes(FTAG, FTHG))
p + geom_point() + geom_smooth(method = "lm", se = FALSE)

tapply(cleaned_data$FTHG, cleaned_data$Season, FUN=mean)
tapply(cleaned_data$FTAG, cleaned_data$Season, FUN=mean)

```

Unsurprisingly the half time result is a strong predictor of the full time result. But it wouldn' be a very good predictive model if you got to use that.

## Match Statistics.
While the match statistics are very interesting I didn't explore them too much as they wouldn't be of huge use in predicting match results in advance. However here are some of my observations.

```{r}
# Relationship between shots and goals
p <- ggplot(cleaned_data, aes(HS, FTHG))
p + geom_point() + geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Home Team Goals as a Function of Shots")
summary(lm(cleaned_data$FTHG~cleaned_data$HS ))

# Score drivers
# 2,3 are team names
match_stats<-cleaned_data[,colnames(cleaned_data)[c(2,3,4,5,11:22)]]
cor(match_stats[,-c(1,2)])
```

There are some pretty strong correlations in here which is unsurprising. As you can't have a goal without a shot etc.

## Gambling Data.

```{r}
p <- ggplot(cleaned_data, aes(B365H, WHH))
p + geom_point() + geom_smooth(method = "lm", se = FALSE)

p <- ggplot(cleaned_data, aes(VCH, WHH))
p + geom_point() + geom_smooth(method = "lm", se = FALSE)
```
I found most of the bookies were in agreement when it came to the odds. These above plots show the very strong correlations. I expect that this data will be quite useful when it comes to trying to predict match results. Well, at least as useful as any.


# Data modelling.
For this section I will explore fitting some predictive models to the data. The goal will be to attempt to predict the outcome of a given match with some degree of accuracy
```{r}
calculate_team_perf_pairs <- function(max_date){
  sub_data <- sub_data[sub_data$Date<max_date, ]
  cleaned_data <- cleaned_data[cleaned_data$Date<max_date, ]
  team_points <-aggregate(
    sub_data$Points, by=list(sub_data$TeamName, sub_data$Opponent),
    FUN=sum)
  
  # Make a function to get the team point ratios for a given Team pair.
  team_points_mat <-cast(team_points, Group.1~Group.2, sum)
  
  team_point_ratios <-round((team_points_mat[,-1])/
                              ((table(cleaned_data$HomeTeam,
                                      cleaned_data$AwayTeam) +
                                  table(cleaned_data$AwayTeam,
                                        cleaned_data$HomeTeam))*3),4)
  #Replace/update row names
  row.names(team_point_ratios)<-colnames(team_point_ratios)
  
  # Replace all  NAs with 0s.
  team_point_ratios <- replace(team_point_ratios,
                               is.na(team_point_ratios), 0)
  
  # Explore what this looks like. Heatmap does heirarchical clustering on the rows and columns.
  heatmap(as.matrix(team_point_ratios))
  
  # Melt the team point raios to get a historical point record.
  # A variable that tells use how well this team has done
  # against this opponent.
  historical_point_record<-melt(cbind(row.names(
    team_point_ratios), team_point_ratios))
  
  colnames(historical_point_record) <- c("TeamName", "Opponent",
                                         "PointRatio")
  
  historical_point_record<- merge(
    historical_point_record, historical_point_record,
    by.x=c("TeamName", "Opponent"), by.y=c("Opponent",
                                           "TeamName"))
  colnames(historical_point_record)[3:4]<-c(
    "HistoricalPointRatio","HistoricalOpponentPointRatio")
  return(historical_point_record)
}

split_date <- "2016-01-01"
# Split data into a training and a testing set so I can validate my predictions.
training_set <- sub_data[sub_data$Date < split_date,]
testing_set <- sub_data[sub_data$Date >= split_date,]

historical_point_record <- calculate_team_perf_pairs(split_date)

truth <- testing_set$Points
#Lets get a baseline. All guess majority class, all wins.
base_preds <- rep(3,196)
confusionMatrix(base_preds, truth)

fix_preds <- function(model, testing_set){
  predictions<-floor(predict(model, testing_set))
  predictions[predictions==2]=3
  return(predictions)
  }

#First lets fit a simple tree. Team and Opponent
tree1 <- rpart(Points ~ TeamName + Opponent, data=training_set)
plot(tree1)
text(tree1)

# These predictions are continuous floats. need to change to ints.
tree_predictions1<-fix_preds(tree1, testing_set)
confusionMatrix(tree_predictions1, truth)

#First lets fit a more complex tree. Adding HomeOrAway
tree2 <- rpart(Points ~ TeamName + Opponent + HomeOrAway, data=training_set)
plot(tree2)
text(tree2)

tree_predictions2 <- fix_preds(tree2, testing_set)
# Actually makes us less accurate. 42.86%
confusionMatrix(tree_predictions2, truth)


party_tree<-ctree(Points ~ TeamName + Opponent + HomeOrAway, data=training_set, controls=ctree_control(maxdepth=6))
plot(party_tree, main="Predicting match results by Decision Tree")
predictions<-fix_preds(party_tree, testing_set)
confusionMatrix(predictions, testing_set$Points)
```

So my trees are more accurate than simple guessing the majority class. 43.88% versus 37.24%. However that is not a huge improvement. Though here I only made use of the teams on both sides and the home/away status. Lets see if some calculated metrics can improve my predictions.

```{r}
training_set<-merge(training_set, historical_point_record, by=c("TeamName", "Opponent"))

testing_set<-merge(testing_set, historical_point_record, by=c("TeamName", "Opponent"))

# Get means and sd for goals for given teams to build assumption that it is a random process
means<-tapply(training_set$Goals, training_set$TeamName, FUN=mean)
sds<-tapply(training_set$Goals, training_set$TeamName, FUN=sd)
goal_frame<-data.frame(cbind(rownames(sds),means, sds))
rownames(goal_frame)<-NULL
colnames(goal_frame)<-c("TeamName","MeanGoals","SDGoals")
goal_frame$MeanGoals<-as.numeric(as.character(
  goal_frame$MeanGoals))
goal_frame$SDGoals<-as.numeric(as.character(
  goal_frame$SDGoals))


table(sub_data$Goals)/sum(sub_data$Goals)
# What distribution are goals drawn from?
# Poisson
norm_goals<-merge(goal_frame, goal_frame, by=NULL)#, type="full")
win_rate<-vector()
draw_rate<-vector()
lose_rate<-vector()
norm_favour<-vector()

for(i in 1:nrow(norm_goals)){
  reps<-10000
  a<-rnorm(reps, mean=norm_goals$MeanGoals.x[i], sd=norm_goals$SDGoals.x[i])
  b<-rnorm(reps, mean=norm_goals$MeanGoals.y[i], sd=norm_goals$SDGoals.y[i])
  sum(a<b)/reps
  apois<-rpois(reps, lambda=norm_goals$MeanGoals.x[i])
  bpois<-rpois(reps, lambda=norm_goals$MeanGoals.y[i])
  norm<-sum(a<b)/reps
  win<-sum(apois>bpois)/reps
  draw<-sum(apois==bpois)/reps
  lose<-sum(apois<bpois)/reps
  
  win_rate<-c(win_rate,win)
  draw_rate<-c(draw_rate,draw)
  lose_rate<-c(lose_rate, lose)
  norm_favour<-c(norm_favour,norm)
}

norm_goals<-cbind(norm_goals,
                  win_rate,
                  draw_rate,
                  lose_rate)
colnames(norm_goals) <- c("TeamName", "MeanGoals", "SDGoals", "Opponent", "OpponentMeanGoals",
                          "OpponentSDGoals", "WinRate", "DrawRate","LoseRate")

training_set<-join(training_set, norm_goals, by=c("TeamName", "Opponent"))
testing_set<-join(testing_set, norm_goals, by=c("TeamName", "Opponent"))

# Replace messy joined names
colnames(training_set) <- gsub('\\.(x|y)','', colnames(training_set),)
colnames(testing_set) <- gsub('\\.(x|y)','', colnames(testing_set),)

```
Lets see how a model does on these new metrics. I fit several other trees at this point but none of them beat the 43.88% accuracy scored above. Until...

```{r}
set.seed(377199)
#rfm = random forest model.
# Increases accuracy to 46.94%
rfm1 <- randomForest(Result ~ TeamName + Opponent +
                      HistoricalPointRatio +
                      HistoricalOpponentPointRatio +
                      WinRate+ LoseRate + DrawRate,
                    data=training_set, ntree=50)
rf_pred<-predict(rfm1, testing_set)
confusionMatrix(rf_pred, testing_set$Result)
# Look at the relative importance of the different features in my random forest.
rfm1$importance

```
46.94% is a nice improvement over 43.88%.

Now lets try predicting using the original wide dataset and the gambling data.

```{r}
set.seed(61313)
# I am dropping all the columns with NA values.
wide_training_set<-cleaned_data[cleaned_data$Date<split_date, -which(colSums(is.na(cleaned_data))>0)]
wide_testing_set<-cleaned_data[cleaned_data$Date>=split_date, -which(colSums(is.na(cleaned_data))>0)]

rfm2<- randomForest(FTR ~ .,
                    data=wide_training_set[,c(2,3,6,23:43)], ntree=101)

rfm2$importance
rf_pred<-predict(rfm2, wide_testing_set)
confusionMatrix(rf_pred, wide_testing_set$FTR)
```
Using the wide dataset, teams and all the complete gambling data my random forest accuracy increases to 51.02%

```{r}
party_tree<-ctree(FTR ~ ., data=wide_training_set[,c(2,3,6,23:43)], controls=ctree_control(maxdepth=6))
plot(party_tree, main="Predicting match results by Decision Tree")
predictions<-predict(party_tree, wide_testing_set)
confusionMatrix(predictions, wide_testing_set$FTR)
```
Lets see how accurate we can get predicting with the match stats. Even though that is gonna be unusable in everyday situations. Makes for a nice tree though and 58.16% accuracy

```{r}
party_tree<-ctree(FTR ~ ., data=wide_training_set[,c(2,3,6,11:43)], controls=ctree_control(maxdepth=6))
plot(party_tree, main="Predicting match results by Decision Tree")
predictions<-predict(party_tree, wide_testing_set)
confusionMatrix(predictions, wide_testing_set$FTR)

rfm2<- randomForest(FTR ~ .,
                    data=wide_training_set[,c(2,3,6,11:43)], ntree=101)
```

Lets try some clustering.

