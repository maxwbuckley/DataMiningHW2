---
title: 'Data Mining Homework 2: Premier League'
author: "Max Buckley"
date: "02/04/2016"
output: pdf_document
---

# Introduction

In this assignment I aim to explore throughly the provided dataset of Premier League soccer matches. From the brief the objective is:

>Your task is to analyse Premier League match data provided since 2010 up to and including last weekend (6 March 2016). You should attempt to uncover interesting and potentially useful patterns and rules which might be used to determine the outcome of the remaining matches in the 2016 league.

I will break my analysis into its logical steps so that I start with data cleaning and preperation, progress to data exploration, and then lastly attempt data modelling and some prediction. I will include all my code in the interests of reproducable research. I did a fair bit more exploring and playing with models. However this document is long enough at twenty plus pages. If you are interested you can take a look at the lot and the revisions in my [Github] repository.

An interesting thing to note is I have absolutely no interest in soccer I may be unaware of or ask naive questions of the data vis-a-vis the soccer afficianados in the class.

# Tools
For this assignment I will be using the statistical programming language [R]. I will be using the [ggplot2] plotting library and rendering the whole thing using [RStudio] and [RMarkdown].

# Data Cleaning
```{r results='hide', message=F, warning=F}
# Libraries.
# Best plotting library ever
library("ggplot2")
# For data munging
library("reshape")
# More data munging
library("reshape2")
# Same
library("plyr")
# Recursive Partitioning decision trees
library("rpart")
# The party package provides nonparametric regression trees
# for nominal, ordinal, numeric, censored, and multivariate
# responses.
library("party")
# Package for classification and regresssion.
library("caret")
# Package for fitting random forests.
library("randomForest")
# Nice date handling
library("lubridate")


# Clear R environment.
rm(list=ls())
# Set working directory .
setwd("~/UCD/DataMining/HW2/")

output_dir <- "CleanedData"
input_dir <- "InputData"

input_csv_files <- dir(input_dir)

# List to store all the data frames.
df_list <- list()
for(i in 1:length(input_csv_files)){
  file <- input_csv_files[i]
  df <- read.csv(paste0(input_dir, "/", file),
                 stringsAsFactors=FALSE)
  # Store a season indicator.
  df$Season <- gsub(".csv", "", file)
  df_list[[i]] <- df
}

# Combine all the data frames into one.
cleaned_data <- rbind.fill(df_list[1:i])
# Format date as proper R date object.
cleaned_data$Date <- as.Date(cleaned_data$Date, "%d/%m/%y")
# Factor desired character columns.
cleaned_data$FTR <- as.factor(cleaned_data$FTR)
cleaned_data$HTR <- as.factor(cleaned_data$HTR)
cleaned_data$HomeTeam <- as.factor(cleaned_data$HomeTeam)
cleaned_data$AwayTeam <- as.factor(cleaned_data$AwayTeam)
cleaned_data$Referee <- as.factor(cleaned_data$Referee)
cleaned_data$Season <- as.factor(gsub("20(\\d+)_(\\d+)","\\1/\\2",
                                      cleaned_data$Season,))
cleaned_data$WeekDay<-wday(cleaned_data$Date, label=TRUE)

# Remove Division as it is a constant. It adds no info.
cleaned_data$Div <- NULL

#Calculate points
HomePoints<-rep(1, nrow(cleaned_data))
HomePoints[cleaned_data$FTR=="H"] <- 3
HomePoints[cleaned_data$FTR=="A"] <- 0
cleaned_data$HomePoints <- HomePoints
AwayPoints<-rep(1,nrow(cleaned_data))
AwayPoints[cleaned_data$FTR=="H"] <- 0
AwayPoints[cleaned_data$FTR=="A"] <- 3
cleaned_data$AwayPoints <-AwayPoints
cleaned_data$TotalGoals <-cleaned_data$FTHG + cleaned_data$FTAG

# Save as output to use later. Use .Rda format to preserve R
# type information in addition to data values.
save(cleaned_data, file = paste0(output_dir, "/",
                                 "cleaned_data.Rda"))
```
With some of my data preprocessing I now had a better idea of what my data source looks like and how it is strucutred.

Given the dataset is currently in wide form and quite difficult to work with I decided to switch it to long form. So rather than having the winner and loser in one row I would have one row for each side and I could then more easily aggregate it.

```{r message=FALSE, warning=FALSE}
options(stringsAsFactors=FALSE)

# Clear R environment.
rm(list=ls())

#This will be used to avoid some division by zero errors later.
ratio_offset<-1e-6

# Set working directory .
setwd("~/UCD/DataMining/HW2/")
# This creates an object called cleaned_data in our environment.
load("CleanedData/cleaned_data.Rda")

# Gets our long form dataset. This function doesn't maintain all the columns.
get_long_data <- function(){
  # Take a subset of our data
  # Team names, results, refs and dates/seasons
  subset <- cleaned_data[,c(1:6, 10, 71, 76, 77, 78)]
  # Convet dataset to long form from wide form.
  sub_data <- melt(subset, id=c("Date", "FTHG", "FTAG", 
                                "FTR", "Referee", "Season", 
                                "HomePoints", "AwayPoints", 
                                "TotalGoals"))
  sub_data <- rename(sub_data, c("value" = "TeamName"))
  sub_data <- rename(sub_data, c("variable" = "HomeOrAway"))
  
  # Calculate the respective points for each team.
  sub_data$Points <- 0
  sub_data$Points[sub_data$HomeOrAway=="AwayTeam"] <-
    sub_data$AwayPoints[sub_data$HomeOrAway=="AwayTeam"]
  sub_data$Points[sub_data$HomeOrAway=="HomeTeam"] <-
    sub_data$HomePoints[sub_data$HomeOrAway=="HomeTeam"]
  
  # Create a factor as it can be easier for prediction.
  sub_data$Result<-as.factor(sub_data$Points)
  levels(sub_data$Result)<-c("L","D","W")
  
  sub_data$Goals <-0
  sub_data$Goals[sub_data$HomeOrAway=="AwayTeam"] <-
    sub_data$FTAG[sub_data$HomeOrAway=="AwayTeam"]
  sub_data$Goals[sub_data$HomeOrAway=="HomeTeam"] <-
    sub_data$FTHG[sub_data$HomeOrAway=="HomeTeam"]
  
  # Opponent
  opposition <-cbind.data.frame(rep(cleaned_data$AwayTeam, 2),
                                rep(cleaned_data$HomeTeam, 2))
  vec<-vector()
  for(i in 1:nrow(opposition)){
    if(sub_data$TeamName[i]==opposition[i, 1]){
     vec[i] <- as.character(opposition[i, 2])
    }
    else{
      vec[i] <- as.character(opposition[i, 1])
    }
  }
  sub_data$Opponent <-as.factor(vec)
  
  # Introduce a calculated metric. goal ratio. Which tells us
  # what proportion of the goals in that match that team scored.
  # To prevent division by zero NaNs. The round later removes this.
  sub_data$GoalRatio<-round((sub_data$Goals + ratio_offset)/
                            (sub_data$TotalGoals + ratio_offset),
                             digits=2)
  return(sub_data)
}

sub_data <- get_long_data()
#Take a peek.
head(sub_data[,-c(2:4)])
```

This long form data will be more useful for prediction in some instances. Now I can predict win/lose/draw for teams rather than say home/away/draw which would have been confounded by the fact that a given team can be either home or away. An important thing to note is there is now 2 rows per match. One row for the home team and one for the away team. Another benefit of this new structure is that I can now aggregate it. Summing the points for a given team easily.

# Data Exploration
## Who are the best teams?
Naively one would assume that the match result and teams playing would appear to be the most imortant factors. So a question to ask is which teams are the best historically and how are these different teams doing?

```{r message=FALSE, warning=FALSE}
# Take another subset
interestcols<-c("Season", "Date", "HomeOrAway", "Referee",
                "TeamName", "Opponent", "Points", "Goals",
                "TotalGoals", "GoalRatio")
formed_data <- sub_data[, interestcols]


## More exploration
numerical <- formed_data[,-c(1,2,3,4,5,6)]
sum_mat<-aggregate(numerical, by=list(formed_data$Season, 
                                      formed_data$TeamName), 
                   FUN=sum)
mean_mat<-aggregate(numerical, by=list(formed_data$Season, 
                                       formed_data$TeamName
                                       ), FUN=mean)
sum_mat$GoalRatio <- mean_mat$GoalRatio
sum_mat <- rename(sum_mat, c("Group.1"="Season",
                             "Group.2"="TeamName"))
sum_mat<-sum_mat[order(as.character(sum_mat$Season), sum_mat$Points, decreasing=TRUE),]
row.names(sum_mat)<-1:120
sum_mat<-ddply(sum_mat, .(Season), transform, Rank = rank(-Points, ties.method="first"))

p<- ggplot(sum_mat, aes(Season, Points, group=TeamName,
                        colour=TeamName))
p + geom_path(alpha=1)+ labs(title = "Team Points by Season"
                             ) + guides(colour=guide_legend
                                        (ncol=2))
```

Of course, looking a this plot we immediately see multiple problems. One is that the 2015/16 season 
is incomplete so all the lines collapse towards the center. Also maybe it is a better question to
ask what is the rank of any given team in a particular year. Note these ranks may not be exactly the same as the actual rank as I am not accounting for goal difference here.


```{r}
p <- ggplot(sum_mat, aes(Season, Rank, group=TeamName,
                        colour=TeamName))
p + geom_path(alpha=1)+ labs(title= "Team Rank by Season") +
  guides(colour=guide_legend(ncol=2))

```
From this, improved chart we can more clearly see that team performance is pertty volatile and hence more difficult predict. Teams can move up and down the leaderboard year to year. We see a lot of the teams at the top of the chart tend to be discontinuos as they get relegated due to poor performance. Thugh it would probably be digest this data in tabular form.

```{r}
# Look at trends over time
rank_by_season <- cast(sum_mat, TeamName ~Season, mean,   value='Rank')
rank_by_season
```

The table at the bottom makes this a little easier to see. The NaN values represent years in which that team did not participate.

Now that I have some idea of what teams are doing well my next exploratory questions are to look at if there are any other interesting relationships in the data.

## Home and Away
Does it make a difference when you are home or away?
```{r}
# How many points on average do you get for a home or away match?
tapply(sub_data$Points, sub_data$HomeOrAway, FUN=mean)

# Examine the relationship between home and away results
prop.table(table(cleaned_data$FTR))

# There is a statistical difference between
t.test(cleaned_data$FTHG, cleaned_data$FTAG, paired=TRUE)
```
It seems my soccer loving friends were correct there seems to be a large difference between home and away performances in favour of home. Home victories are ~50% more likely than away victories.

```{r}
# Plot the relationship between home and away goals
p <- ggplot(cleaned_data, aes(FTAG, FTHG))
p + geom_point() + geom_smooth(method = "lm", se = FALSE)
```
## Day of the week
It would be interesting to see if performance changes as a function of day of the week. Above in data cleaning I added a variable weekday. So here I will explore it.

```{r}
# Plot the relationship between goals and day of the week.
p <- ggplot(cleaned_data, aes(WeekDay, TotalGoals))
p + geom_boxplot()

# How many matches have we seen on each day?
table(cleaned_data$WeekDay)

# Why does home advantage appear biggest on a Saturday? More home attendees?
# We also have the most obserations on Saturdays so should be more certain
# of our estimate.
tapply(cleaned_data$HomePoints, cleaned_data$WeekDay, FUN=mean) -
  tapply(cleaned_data$AwayPoints, cleaned_data$WeekDay, FUN=mean)

```
We don't see many matches on Thursdays or Fridays.

## Referees
```{r}
# Are there differences between referees?
tapply(cleaned_data$TotalGoals, cleaned_data$Referee, FUN=mean)

p <- ggplot(cleaned_data, aes(Referee, TotalGoals))
p + geom_boxplot() + geom_jitter() + labs(
  title= "Total Goals by referee.") + theme(
    axis.ticks = element_blank(), axis.text.x = element_blank())

```

There appears to be no relationship between total goals and referee. Which is probably for the best as otherwise we would have some serious questions to ask.

## Half time vs. Full time.
```{r}
# Relationship betwen half time result and full time result.
prop.table(table(cleaned_data$FTR, cleaned_data$HTR),2)
```

Unsurprisingly the half time result is a super strong predictor of the full time result. But it wouldn' be a very good predictive model if we got to use that. As it would imply we were predicting at the half time whistle.

## Match Statistics.
While the match statistics are very interesting I didn't explore them too much as they wouldn't be of huge use in predicting match results in advance. However here are some of my observations.

```{r}
# Relationship between shots and goals
p <- ggplot(cleaned_data, aes(HS, FTHG))
p + geom_point() + geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Home Team Goals as a Function of Shots")
summary(lm(cleaned_data$FTHG~cleaned_data$HS ))

# Score drivers
# 2,3 are team names
match_stats<-cleaned_data[,colnames(cleaned_data)[c(2,3,4,5,11:22)]]
cor(match_stats[,-c(1,2)])
```

There are some pretty strong correlations in here which is unsurprising. As you can't have a goal without a shot on target and you can't have a shot on target without a shot, etc...

## Gambling Data.
My prior assumption is that the bookie data would make for decent predictions and that all the bookies would be highly correlated.

```{r}
# Plot two bookies odds against one another.
p <- ggplot(cleaned_data, aes(B365H, WHH))
p + geom_point() + geom_smooth(method = "lm", se = FALSE)

p <- ggplot(cleaned_data, aes(VCH, WHH))
p + geom_point() + geom_smooth(method = "lm", se = FALSE)
```
As expected, I found most of the bookies were in agreement when it came to the odds. These above plots show the very strong correlations.

# Data modelling.
For this section I will explore fitting some predictive models to the data. The goal will be to attempt to predict the outcome of a given match with some degree of accuracy. To do this I will try fitting some simple models. Then try to derive some more interesting calculated metrics from the data and see if they work.

I will then trying fitting some more complex models and see if I can improve my predictions. The objective here is demonstration rather than accuracy so I will not be tuning and optimizing models but rather fitting them out of the box.

I will use all the data up to end of 2015 as my training set and I will use 2016 data to date as my testing set.
```{r}
get_team_perf_ratio_matrix <- function(max_date){
  sub_data <- sub_data[sub_data$Date<max_date, ]
  cleaned_data <- cleaned_data[cleaned_data$Date<max_date, ]
  team_points <-aggregate(
    sub_data$Points, by=list(sub_data$TeamName, sub_data$Opponent),
    FUN=sum)
  
  # Make a function to get the team point ratios for a given Team pair.
  team_points_mat <-cast(team_points, Group.1~Group.2, value='x', sum)
  
  team_point_ratios <-round((team_points_mat[,-1])/
                              ((table(cleaned_data$HomeTeam,
                                      cleaned_data$AwayTeam) +
                                  table(cleaned_data$AwayTeam,
                                        cleaned_data$HomeTeam))*3),4)
  #Replace/update row names
  row.names(team_point_ratios)<-colnames(team_point_ratios)
  
  # Replace all  NAs with 0s.
  team_point_ratios <- replace(team_point_ratios,
                               is.na(team_point_ratios), 0)
  return(team_point_ratios)
  }
  
calculate_team_perf_pairs <- function(max_date){
 team_point_ratios<-get_team_perf_ratio_matrix(max_date)

  
  # Melt the team point raios to get a historical point record.
  # A variable that tells use how well this team has done
  # against this opponent.
  historical_point_record<-melt(cbind(row.names(
    team_point_ratios), team_point_ratios))
  
  colnames(historical_point_record) <- c("TeamName", "Opponent",
                                         "PointRatio")
  
  historical_point_record<- merge(
    historical_point_record, historical_point_record,
    by.x=c("TeamName", "Opponent"), by.y=c("Opponent",
                                           "TeamName"))
  colnames(historical_point_record)[3:4]<-c(
    "HistoricalPointRatio","HistoricalOpponentPointRatio")
  return(historical_point_record)
}

split_date <- "2016-01-01"
# Split data into a training and a testing set so I can validate my predictions.
training_set <- sub_data[sub_data$Date < split_date,]
testing_set <- sub_data[sub_data$Date >= split_date,]

historical_point_record <- calculate_team_perf_pairs(split_date)

# I am dropping all the columns with NA values.
wide_training_set<-cleaned_data[cleaned_data$Date<split_date,
                                -which(colSums(is.na(cleaned_data))>0)]
wide_testing_set<-cleaned_data[cleaned_data$Date>=split_date,
                               -which(colSums(is.na(cleaned_data))>0)]

# Target prediction values.
truth <- wide_testing_set$FTR
#Lets get a baseline. All guess majority class, all wins.
base_preds <- rep(names(which.max(table(wide_training_set$FTR))), 98)
confusionMatrix(base_preds, truth)

# Guessing all home victories leads us to 42.86% accuracy

tree1<-ctree(FTR~HomeTeam+AwayTeam, data=wide_training_set)

plot(tree1, main="Predicting match results by Team Names")
predictions<-predict(tree1, wide_testing_set)
confusionMatrix(predictions, wide_testing_set$FTR)
```
In a naive model we assumed the majority class for all matches. All Home victories. This lead to predictive accuracy of 42.86%. Using team names alone (Home and Away) we managed to increase our predictive accuracy to 46.94%. Now lets try predicting using the original wide dataset and the gambling data.

```{r}
tree2<-ctree(FTR~., data=wide_training_set[,c(2,3,6,23:43)])

plot(tree2, main="Predicting match results by Gambling data with team names.")
predictions<-predict(tree2, wide_testing_set)
confusionMatrix(predictions, wide_testing_set$FTR)
# The decision tree splits on the gambling data, ignoring the team names.

set.seed(61313)

rfm2<- randomForest(FTR ~ .,
                    data=wide_training_set[,c(2,3,6,23:43)], ntree=101)

rfm2$importance
rf_pred<-predict(rfm2, wide_testing_set)
confusionMatrix(rf_pred, wide_testing_set$FTR)
```
Using the wide dataset, teams and all the complete gambling data my random forest accuracy increases to 47.96%. Much better than random guessing. Though it would be difficult to profit off this insight as you are attempting to use the bookies probably better predictions to build your own prediction.

# Predict using match stats
Lets see how accurate we can get predicting with the match stats. Even though that is gonna be unusable in everyday situations. Makes for a nice tree though and a formidable 58.16% accuracy

```{r}
tree3<-ctree(FTR ~ ., data=wide_training_set[,c(2,3,6,11:43)],
             controls=ctree_control(maxdepth=6))
plot(tree3, main="Predicting match results by Decision Tree")
predictions<-predict(tree3, wide_testing_set)
confusionMatrix(predictions, wide_testing_set$FTR)
```

# Try some clusering
Lets try some clustering. We can again use all the data here as I won't be predicting on the clusters. This is unsupervised rather than supervised learning.

# Clustering teams by win ratios
```{r}
team_point_ratios<- get_team_perf_ratio_matrix("2017-01-01")

win_clusters <- kmeans(team_point_ratios, 6)
win_clusters$size
table(row.names(team_point_ratios), win_clusters$cluster)

d<-dist(team_point_ratios)
hc<-hclust(d)
plot(hc, main="Hierarchical clustering by team point ratio performance")
```
The teams that join lower down the tree are more similar than the ones who join higher up. Looking at this dendrograph we see a cluster on the far left of related teams. (Chelsea, Man United, Man City and Arsenal) I would say these are groupeed as winners. Teams that tend to beat other teams. Similarly the far right teams (Wolves, Reading, QPR etc.) are the relegaters. The teams the tend toward the bottom of the league and drop in and out with relegation.

Of course this graph is treating all matches equally so more recent performance is not being weighed any way more heavily than  historic performance.
```{r}
# Explore what this looks like. Heatmap does heirarchical clustering
# on the rows and columns.
heatmap(as.matrix(team_point_ratios))

```

#Conclusion

In the above report I have explored the provided premier league data. TBC.

[Github]:https://github.com/maxwbuckley/DataMiningHW2
[ggplot2]:http://ggplot2.org/
[R]:http://www.r-project.org/
[RStudio]:http://www.rstudio.com/
[RMarkdown]:http://rmarkdown.rstudio.com/
